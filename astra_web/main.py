import os
from typing import Any, Type

from fastapi import Body, Depends, FastAPI, HTTPException, Query, status
from fastapi.responses import ORJSONResponse, RedirectResponse
from pydantic import BaseModel

from .dtypes import FloatPrecision
from .auth.auth_schemes import api_key_auth
from .features.actions import (
    get_all_varying_features,
    get_features,
    make_simulation_feature_table,
)
from .features.schemas.io import Features, FeatureTable, FeatureTableInput
from .field.actions import (
    delete_field_table,
    list_field_table_file_names,
    read_field_table,
    write_field_table,
)
from .field.schemas.field_table import FieldTable
from .generator.actions import (
    delete_particle_distribution,
    dispatch_particle_distribution_generation,
    list_generator_ids,
    list_particle_distribution_states,
    load_generator_data,
    write_particle_distribution,
)
from .generator.schemas.io import GeneratorData, GeneratorDispatchOutput, GeneratorInput
from .generator.schemas.particles import Particles
from .host_localizer import (
    HostLocalizerTypes,
    Hosts,
    LocalHostLocalizer,
    SLURMHostLocalizer,
    SLURMJobState,
)
from .host_localizer.schemas.slurm import (
    SLURMConfiguration,
    SLURMDispatchedIDsOutput,
    SLURMDispatchedJobsOutput,
)
from .simulation.actions import (
    compress_simulation,
    delete_simulation,
    dispatch_simulation_run,
    list_simulation_ids,
    list_simulation_states,
    load_simulation_data,
    uncompress_simulation,
)
from .simulation.schemas.io import (
    SimulationDataWithMeta,
    SimulationDispatchOutput,
    SimulationInput,
)
from .status import DispatchStatus

tags_metadata = [
    {
        "name": "particles",
        "description": "All CRUD methods for particle distributions.\
                        Distributions are generated by ASTRA generator binary.",
    },
    {
        "name": "fields",
        "description": "All CRUD methods for fields.\
                        Fields can be uploaded for use in simulations.",
    },
    {
        "name": "simulations",
        "description": "All CRUD methods for beam dynamics simulations.\
                        Simulations are run by ASTRA binary.",
    },
    {
        "name": "features",
        "description": "Extract features across the entire database.",
    },
    {
        "name": "slurm",
        "description": "Configure and diagnose the SLURM backend.",
    },
]


app = FastAPI(
    title="ASTRA WebAPI",
    description="This is an API wrapper for the ASTRA simulation code developed \
                 by K. Floettmann at DESY Hamburg. For more information, refer to the official \
                 [website](https://www.desy.de/~mpyflo/).",
    version="4.0.0",
    contact={
        "name": "Jens Kwasniok",
        "email": "jens.kwasniok@desy.de",
    },
    root_path=os.getenv("SERVER_ROOT_PATH", ""),
    openapi_tags=tags_metadata,
    default_response_class=ORJSONResponse,
)


def _all_models(cls: Type[BaseModel] = BaseModel) -> set[Type[BaseModel]]:
    """Return a set of all subclasses of a class (default=BaseModel), recursively."""
    subs: set[Type[BaseModel]] = set(cls.__subclasses__())
    for sub in cls.__subclasses__():
        subs.update(_all_models(sub))
    return subs


def _save_alias_table(path: str) -> None:
    """Save a table of all models and their fields with aliases."""
    table: dict[str, dict[str, str | None]] = {}
    for model in _all_models():
        aliases: dict[str, str | None] = {
            f: i.alias for f, i in model.model_fields.items() if i.alias is not None
        }
        if aliases:
            table[model.__name__] = aliases

    with open(path, "w") as f:
        for model_name, fields in table.items():
            f.write(f"{model_name}:\n")
            for field_name, alias in fields.items():
                f.write(f" - {field_name}: {alias}\n")


_save_alias_table(path="alias_table.txt")


@app.get("/", include_in_schema=False)
async def root():
    return RedirectResponse(url="/docs")


@app.get(
    "/particles/ids",
    dependencies=[Depends(api_key_auth)],
    tags=["particles"],
)
def list_particle_distribution_ids(
    state: DispatchStatus | None = Query(default=None),
) -> list[str]:
    """
    Returns a list of particle distribution IDs.
    """
    localizer = LocalHostLocalizer.instance()
    return list_generator_ids(localizer, state=state)


@app.get(
    "/particles/states",
    dependencies=[Depends(api_key_auth)],
    tags=["particles"],
)
async def _list_particle_distribution_states(
    gen_ids=Body(default=None, examples=[["gen_id_1", "gen_id_2"]]),
) -> list[tuple[str, DispatchStatus]]:
    # local
    local_localizer = LocalHostLocalizer.instance()
    return list_particle_distribution_states(local_localizer, gen_ids=gen_ids)


@app.post(
    "/particles",
    dependencies=[Depends(api_key_auth)],
    tags=["particles"],
)
async def dispatch_particle_distribution_generation_(
    generator_input: GeneratorInput,
    host: Hosts = Query(default=Hosts.LOCAL),
    timeout: int = Query(default=600),
) -> GeneratorDispatchOutput:
    local_localizer = LocalHostLocalizer.instance()
    host_localizer = HostLocalizerTypes.get_localizer(host)
    return await dispatch_particle_distribution_generation(
        generator_input,
        local_localizer,
        host_localizer,
        timeout=timeout,
    )


@app.put(
    "/particles",
    dependencies=[Depends(api_key_auth)],
    tags=["particles"],
)
def upload_particle_distribution(
    output: Particles,
    comment: str | None = Body(
        default=None, description="Optional comment for the particle distribution."
    ),
) -> dict[str, str]:
    localizer = LocalHostLocalizer.instance()
    gen_id = write_particle_distribution(output, localizer, comment=comment)
    return {"gen_id": gen_id}


@app.get(
    "/particles/{gen_id}",
    dependencies=[Depends(api_key_auth)],
    tags=["particles"],
)
def download_generator_results(gen_id: str) -> GeneratorData:
    localizer = LocalHostLocalizer.instance()
    output = load_generator_data(gen_id, localizer)
    if output is None:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Generator output for '{gen_id}' not found.",
        )
    return output


@app.delete(
    "/particles/{gen_id}",
    dependencies=[Depends(api_key_auth)],
    tags=["particles"],
)
async def delete_particle_distribution_(gen_id: str) -> None:
    localizer = LocalHostLocalizer.instance()
    blocking_links = delete_particle_distribution(gen_id, localizer)
    if blocking_links is not None:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Particle distribution '{gen_id}' cannot be deleted because it is referenced by: {blocking_links}",
        )


@app.get(
    "/fields",
    dependencies=[Depends(api_key_auth)],
    tags=["fields"],
)
async def list_field_table_file_names_() -> list[str]:
    localizer = LocalHostLocalizer.instance()
    return list_field_table_file_names(localizer)


@app.get(
    "/fields/{file_name}",
    dependencies=[Depends(api_key_auth)],
    tags=["fields"],
)
async def download_field_table_(file_name: str) -> FieldTable:
    localizer = LocalHostLocalizer.instance()
    try:
        table = read_field_table(file_name, localizer)
    except FileNotFoundError:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Field table '{file_name}' not found.",
        )
    return table


@app.put(
    "/fields/{file_name}",
    dependencies=[Depends(api_key_auth)],
    tags=["fields"],
)
async def upload_field_table_(file_name: str, table: FieldTable) -> None:
    localizer = LocalHostLocalizer.instance()
    try:
        write_field_table(file_name, table, localizer)
    except FileExistsError:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Field table '{file_name}' already exists.",
        )


@app.delete(
    "/fields/{file_name}",
    dependencies=[Depends(api_key_auth)],
    tags=["fields"],
)
async def delete_field_table_(file_name: str) -> None:
    localizer = LocalHostLocalizer.instance()
    blocking_links = delete_field_table(file_name, localizer)
    if blocking_links:
        raise HTTPException(
            status_code=status.HTTP_409_CONFLICT,
            detail=f"Field table '{file_name}' cannot be deleted because it is referenced by: {blocking_links}",
        )


@app.get(
    "/simulations/ids",
    dependencies=[Depends(api_key_auth)],
    tags=["simulations"],
)
def list_simulation_ids_(
    state: DispatchStatus | None = Query(default=None),
) -> list[str]:
    """
    Returns a list of  simulation IDs.
    """
    localizer = LocalHostLocalizer.instance()
    return list_simulation_ids(localizer, state=state)


@app.get(
    "/simulations/states",
    dependencies=[Depends(api_key_auth)],
    tags=["simulations"],
)
async def _list_simulation_states(
    sim_ids=Body(default=None, examples=[["sim_id_1", "sim_id_2"]]),
) -> list[tuple[str, DispatchStatus]]:
    # local
    local_localizer = LocalHostLocalizer.instance()
    return list_simulation_states(local_localizer, sim_ids=sim_ids)


@app.post(
    "/simulations",
    dependencies=[Depends(api_key_auth)],
    tags=["simulations"],
)
async def dispatch_simulation(
    simulation_input: SimulationInput,
    host: Hosts = Query(default=Hosts.LOCAL),
) -> SimulationDispatchOutput:
    # local
    local_localizer = LocalHostLocalizer.instance()
    host_localizer = HostLocalizerTypes.get_localizer(host)
    return await dispatch_simulation_run(
        simulation_input, local_localizer, host_localizer
    )


@app.get(
    "/simulations/{sim_id}",
    dependencies=[Depends(api_key_auth)],
    tags=["simulations"],
)
def download_simulation_data(sim_id: str) -> SimulationDataWithMeta:
    """
    Returns the output of a specific ASTRA simulation on the requested server depending
    on the given ID.
    """
    localizer = LocalHostLocalizer.instance()
    output = load_simulation_data(sim_id, localizer)
    if output is None:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=f"Simulation '{sim_id}' not found.",
        )
    else:
        return output


@app.delete(
    "/simulations/{sim_id}",
    dependencies=[Depends(api_key_auth)],
    tags=["simulations"],
)
async def delete_simulation_(sim_id: str) -> None:
    localizer = LocalHostLocalizer.instance()
    return delete_simulation(sim_id, localizer)


@app.put(
    "/simulations/{sim_id}/compress",
    dependencies=[Depends(api_key_auth)],
    tags=["simulations"],
    description="Internally compresses some simulation files to save disk space on server. Deletes original files. Compression can be LOSSY!",
)
async def compress_simulation_(
    sim_id: str,
    precision: FloatPrecision = Query(
        default=FloatPrecision.FLOAT64,
        description="Floating point data type to be used internally.",
    ),
    max_rel_err: float = Query(
        default=1e-4,
        description="Maximum allowed element-wise relative error during lossy compression.",
    ),
) -> None:
    localizer = LocalHostLocalizer.instance()
    try:
        return compress_simulation(
            sim_id,
            localizer,
            precision=precision,
            max_rel_err=max_rel_err,
        )
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=str(e),
        )


@app.put(
    "/simulations/{sim_id}/uncompress",
    dependencies=[Depends(api_key_auth)],
    tags=["simulations"],
    description="Internally uncompresses previously compressed simulation files if available. Restored data may not be identical to original data due to LOSSY compression.",
)
async def uncompress_simulation_(
    sim_id: str,
    high_precision: bool = Query(
        default=True,
        description="If `true`, writes floating point numbers with high precision (12 digits after the decimal point).  If `false`, uses 4 digits after the decimal point. See ASTRA documentation for details.",
    ),
) -> None:
    localizer = LocalHostLocalizer.instance()
    try:
        return uncompress_simulation(sim_id, localizer, high_precision=high_precision)
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_404_NOT_FOUND,
            detail=str(e),
        )


# note: get is not allowed with a body, so post is used as a workaround
# see: https://datatracker.ietf.org/doc/html/rfc9110#name-get
@app.post(
    "/features",
    dependencies=[Depends(api_key_auth)],
    tags=["features"],
)
async def download_features_table(
    sim_ids: list[str] | None = Body(default=None, examples=[["sim_id_1", "sim_id_2"]]),
    features: FeatureTableInput = Body(
        ...,
        examples=[
            [
                "sim_id",
                "generator.input.particle_count",
                "simulation.output.emittance_z",
            ]
        ],
    ),
    filter_by_comment: str | None = Body(
        default=None,
        examples=["experiment v.*"],
        help="Optional regex to filter simulations by their comment.",
    ),
) -> FeatureTable:
    """
    Returns a table of requested features.

    The `sim_ids` parameter is an optional list of (finished) simulation IDs for which the features should be computed.
    If none are provided, the features will be computed for all finished simulations in the database.

    The `filter_by_comment` parameter is an optional regex string to filter simulations by their comment field.
    If none is provided, no filtering by comment is applied.

    Both filter options can be combined.

    See schema `Features` for a list of all available features.
    """
    localizer = LocalHostLocalizer.instance()
    try:
        return make_simulation_feature_table(
            sim_ids,
            features,
            localizer,
            filter_by_comment=filter_by_comment,
        )
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e),
        )


# note: get is not allowed with a body, so post is used as a workaround
# see: https://datatracker.ietf.org/doc/html/rfc9110#name-get
@app.post(
    "/features/varying",
    dependencies=[Depends(api_key_auth)],
    tags=["features"],
)
async def download_varying_features(
    sim_ids: list[str] | None = Body(default=None, examples=[["sim_id_1", "sim_id_2"]]),
) -> dict[str, list[Any]]:
    """
    Returns all varying features of simulations. Features which are identical across all simulations are skipped.

    The `sim_ids` parameter is a list of (finished) simulation IDs for which the features should be computed.
    If none are provided, the features will be computed for all simulations in the database.
    """
    localizer = LocalHostLocalizer.instance()
    return get_all_varying_features(sim_ids, localizer)


# note: get is not allowed with a body, so post is used as a workaround
# see: https://datatracker.ietf.org/doc/html/rfc9110#name-get
# note: This enpoint is somewhat redundant with the above, but it is kept for discoverability and consistency.
@app.post(
    "/features/{sim_id}",
    dependencies=[Depends(api_key_auth)],
    tags=["features"],
)
async def download_all_features_for_simulation(
    sim_id: str,
) -> Features:
    """
    Returns all features for a specific simulation run.
    note: May include raw and meta data as well.
    """
    localizer = LocalHostLocalizer.instance()
    try:
        return get_features(sim_id, localizer)
    except ValueError as e:
        raise HTTPException(
            status_code=status.HTTP_400_BAD_REQUEST,
            detail=str(e),
        )


@app.get(
    "/slurm/configuration",
    dependencies=[Depends(api_key_auth)],
    tags=["slurm"],
)
async def download_slurm_configuration() -> SLURMConfiguration:
    slurm_localizer = SLURMHostLocalizer.instance()
    return slurm_localizer.configuration


@app.put(
    "/slurm/configuration",
    dependencies=[Depends(api_key_auth)],
    tags=["slurm"],
)
async def configure_slurm(config: SLURMConfiguration) -> None:
    slurm_localizer = SLURMHostLocalizer.instance()
    slurm_localizer.configure(config)


@app.put(
    "/slurm/configuration/user_token",
    dependencies=[Depends(api_key_auth)],
    tags=["slurm"],
)
async def update_slurm_user_token(
    value: str = Query(..., description="The new SLURM user token.")
) -> None:
    """
    Exclusively updates the SLURM user token used for authentication with the SLURM REST API and nothing more.

    Usefull in case the previous token has expired or is no longer valid.
    """
    slurm_localizer = SLURMHostLocalizer.instance()
    slurm_localizer.update_user_token(value)


@app.get(
    "/slurm/ping",
    dependencies=[Depends(api_key_auth)],
    tags=["slurm"],
)
async def ping_slurm(
    timeout: int | None = Query(
        default=None, description="SLURM REST API request timeout in seconds."
    ),
) -> dict[str, Any]:
    slurm_localizer = SLURMHostLocalizer.instance()
    return await slurm_localizer.ping(timeout)  # type: ignore


@app.get(
    "/slurm/diagnose",
    dependencies=[Depends(api_key_auth)],
    tags=["slurm"],
)
async def diagnose_slurm(
    timeout: int | None = Query(
        default=None, description="SLURM REST API request timeout in seconds."
    ),
) -> dict[str, Any]:
    slurm_localizer = SLURMHostLocalizer.instance()
    return await slurm_localizer.diagnose(timeout)  # type: ignore


@app.get(
    "/slurm/jobs",
    dependencies=[Depends(api_key_auth)],
    tags=["slurm"],
)
async def list_slurm_jobs(
    timeout: int | None = Query(
        default=None, description="SLURM REST API request timeout in seconds."
    ),
) -> SLURMDispatchedJobsOutput:
    """
    Lists jobs currently managed by SLURM.

    see: https://slurm.schedmd.com/rest_api.html#slurmdbV0043GetJobs
    """
    slurm_localizer = SLURMHostLocalizer.instance()
    return await slurm_localizer.list_jobs(timeout=timeout)


@app.get(
    "/slurm/jobs/ids",
    dependencies=[Depends(api_key_auth)],
    tags=["slurm"],
)
async def list_dispatched_ids_by_state(
    state: SLURMJobState = Query(
        default=None, description="Filter by SLURM job state."
    ),
    timeout: int | None = Query(
        default=None, description="SLURM REST API request timeout in seconds."
    ),
) -> SLURMDispatchedIDsOutput:
    """
    Lists all dispatched IDs currently managed by SLURM filtered by state.
    """
    slurm_localizer = SLURMHostLocalizer.instance()
    return await slurm_localizer.list_dispatched_ids_by_state(
        state=state, timeout=timeout
    )
